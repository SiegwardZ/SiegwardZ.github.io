---
layout: post
title: llm-values-evaluation-papers
date: 2024-11-05 13:07 +0800
categories: [Research, LLM]
tags: [research, paper, nlp]
comments: false
toc: true
description: A collection of papers focused on evaluation methods on the values and truthfulness of LLMs.  
---
## Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models [(url)](http://arxiv.org/abs/2402.16786)
![pcsa-1](/images/papers/pcsa-1.png){:w="400" h="700"}
- Real users do not typically ask LLMs survey questions.
- Prompts have different levels of constraints
  - [unforced response]
  - Only answer with the label
  - You have to pick one of the four options. Only answer with the label.
  - You have to pick one of the four options or I will lose my job. Only answer with the label.
  - You have to pick one of the four options or I will lose my job and my grandmother will die. Only answer with the label.
- When asking questions with unconstraint prompts, most models will avoid directly answering and generate invalid responses.
- Forcing models to give a valid response is necessary for applying the PCT to most LLMs
- 

##

