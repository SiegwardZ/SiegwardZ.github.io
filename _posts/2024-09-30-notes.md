---
layout: post
title: Notes
categories: [Technology,Notes]
tags: [technology]
description: A technical notes for recording encountered issues and techniques.
comments: false
math: true
date: 2024-09-30 21:00 +0800
---
## AI Models
### CLIP Encoder
Huggingface的CLIP Model类如下
```python
text_model = CLIPTextModel._from_config(text_config)
self.text_model = text_model.text_model

vision_model = CLIPVisionModel._from_config(vision_config)
self.vision_model = vision_model.vision_model

self.visual_projection = nn.Linear(self.vision_embed_dim, self.projection_dim, bias=False)
self.text_projection = nn.Linear(self.text_embed_dim, self.projection_dim, bias=False)
```
实际encode过程如下(vision 同理)
```python
text_outputs = self.text_model(
          input_ids=input_ids,
          attention_mask=attention_mask,
          position_ids=position_ids,
          output_attentions=output_attentions,
          output_hidden_states=output_hidden_states,
          return_dict=return_dict,
      )

pooled_output = text_outputs[1]
text_features = self.text_projection(pooled_output)
```
clip model相当于先用各自的encoder encode出一个embedding之后，做了一次pooling，最后再用linear projector投影到相同的特征空间中。这里的pooling操作取的是eos_token的hiddens_state。

比如```openai/clip-vit-large-patch14-336```的model，

其text经过text model输出的是一个(1,200,768)的tensor，即(batch,seq_len,hidden_size)，pooled之后得到(1,768)的tensor，最后经过projector投影成(1,1024)的feature embedding

而image经过imageprocessor先变成(1,3,336,336)的tensor，即(batch,channel,resolution_width,resolution_height)，经过vision model输出的是一个(1,577,1024)的tensor，pooled之后得到(1,1024)的tensor，最后经过projector投影成(1,1024)的feature embedding。

注意这里之所是(1,577,1024)的shape是因为该clip model划分的patch数为14，宽高都是336，那么划分出的patch总个数为

$$
\frac{336}{14} \times \frac{336}{14} = 24 \times 24 = 576
$$

再加上开头的CLS token共577个token。pooling时也是使用CLS token作为pooling token。

### Cross-Attention
```python
if is_cross_attention:
    key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))
    value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))
    attention_mask = encoder_attention_mask
elif past_key_value is not None:
    key_layer = self.transpose_for_scores(self.key(hidden_states))
    value_layer = self.transpose_for_scores(self.value(hidden_states))
    key_layer = torch.cat([past_key_value[0], key_layer], dim=2)
    value_layer = torch.cat([past_key_value[1], value_layer], dim=2)
else:
    key_layer = self.transpose_for_scores(self.key(hidden_states))
    value_layer = self.transpose_for_scores(self.value(hidden_states))
```
如果是cross attention的话，在decoder层传入的encoder_hidden_states参数是用来在cross attention中做为key和value的。query仍为input_ids。

## Pytorch 
### gradient 计算
如果已知梯度公式但没法表示原函数，有如下几种方法计算梯度：
1. 根据梯度反推出另一个原函数，用那个原函数作为loss function计算梯度，常见操作如将 $ \nabla f(x) $ 替换成 $ f(x) \nabla log f(x) $
2. 根据梯度公式，通过冻结部分参数的方式实现梯度计算，即把不需要计算梯度的部分当作常数，将它们放在no_grad下计算

### 查看module的gradient
查看module参数的梯度:
```python
for name, param in model.named_parameters():
    if param.grad is not None:
        print(f"grad of param {name}: \n {param.grad}")
    else:
        print(f"param {name} has no grad")
```
### 两次调用loss backward后报错 计算图不能使用两次
看看是不是调用`optimizer.zero_grad()`后复用了前一个loss的计算图
每次清空梯度后需要从头开始计算下一个loss



## Markdown 
### 并排显示表格
1. html

```html
<p align="center">
    <img src="" alt="Image 1" width="45%" />
    <img src="" alt="Image 2" width="45%" />
</p>
```

2. table
```markdown
| ![Image 1](image1.png) | ![Image 2](image2.png) |
|------------------------|------------------------|
```

### 展示html代码块
注意\`\`\`前如果是html，需要空一行

## Python
### remove dirs
使用```os.removedirs(path)```会遇到检测到目录非空而无法删除的问题，可换成```shutil.rmtree(path)```，注意需要```import shutil```

### vars转dict
使用```vars()```可以转换特定对象为dict格式，等价于调用```object.__dict__()```，如将argparse返回的namespace转换成config dict

### 调用摄像头
```python
import numpy as np
import cv2

cap = cv2.VideoCapture(0)
w = int(cap.get(3))  # 获取视频的width
h = int(cap.get(4))  # 获取视频的height
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('output.avi',fourcc, 30.0, (w, h))

while(cap.isOpened()):
    ret, frame = cap.read()
    if ret==True:
        frame = cv2.flip(frame,1)
        out.write(frame) # 保存视频
        cv2.imshow('frame', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    else:
        break

cap.release()
out.release()
cv2.destroyAllWindows()
```
ref:[https://blog.csdn.net/qq_45779334/article/details/114676905](https://blog.csdn.net/qq_45779334/article/details/114676905)

## Linux
### Shell同时输出到文件和控制台
```bash
<your program> | tee <your file path>
```
### 查看tcp端口占用
```bash
lsof -wni tcp:4000
```
