---
layout: post
title: Notes
categories: [Technology,Notes]
tags: [technology]
description: A technical notes for recording encountered issues and techniques.
comments: false
math: true
date: 2024-09-30 21:00 +0800
---
## AI Models
### CLIP Encoder
Huggingface的CLIP Model类中的部分代码如下
```python
text_model = CLIPTextModel._from_config(text_config)
self.text_model = text_model.text_model

vision_model = CLIPVisionModel._from_config(vision_config)
self.vision_model = vision_model.vision_model

self.visual_projection = nn.Linear(self.vision_embed_dim, self.projection_dim, bias=False)
self.text_projection = nn.Linear(self.text_embed_dim, self.projection_dim, bias=False)
```
实际encode的主要过程如下(vision 同理)
```python
text_outputs = self.text_model(
          input_ids=input_ids,
          attention_mask=attention_mask,
          position_ids=position_ids,
          output_attentions=output_attentions,
          output_hidden_states=output_hidden_states,
          return_dict=return_dict,
      )

pooled_output = text_outputs[1]
text_features = self.text_projection(pooled_output)
```
clip model相当于先用各自的encoder encode出一个embedding之后，做了一次pooling，最后再用linear projector投影到相同的特征空间中。这里的pooling操作取的是eos_token的hiddens_state。

比如```openai/clip-vit-large-patch14-336```的model，

其text经过text model输出的是一个(1,200,768)的tensor，即(batch,seq_len,hidden_size)，pooled之后得到(1,768)的tensor，最后经过projector投影成(1,1024)的feature embedding。

而image经过imageprocessor先变成(1,3,336,336)的tensor，即(batch, channel, resolution_width, resolution_height)，经过vision model输出的是一个(1,577,1024)的tensor，pooled之后得到(1,1024)的tensor，最后经过projector投影成(1,1024)的feature embedding。

注意这里之所是(1,577,1024)的shape是因为该clip model划分的patch数为14，宽高都是336，那么划分出的patch总个数为

$$
\frac{336}{14} \times \frac{336}{14} = 24 \times 24 = 576
$$ 

再加上开头的CLS token共577个token。pooling时也是使用CLS token作为pooling token。

### Cross-Attention
```python
if is_cross_attention:
    key_layer = self.transpose_for_scores(self.key(encoder_hidden_states))
    value_layer = self.transpose_for_scores(self.value(encoder_hidden_states))
    attention_mask = encoder_attention_mask
elif past_key_value is not None:
    key_layer = self.transpose_for_scores(self.key(hidden_states))
    value_layer = self.transpose_for_scores(self.value(hidden_states))
    key_layer = torch.cat([past_key_value[0], key_layer], dim=2)
    value_layer = torch.cat([past_key_value[1], value_layer], dim=2)
else:
    key_layer = self.transpose_for_scores(self.key(hidden_states))
    value_layer = self.transpose_for_scores(self.value(hidden_states))
```
如果是cross attention的话，在decoder层传入的encoder_hidden_states参数是用来在cross attention中做为key和value的。query仍为input_ids。

## Pytorch 
### gradient 计算
如果已知梯度公式但没法表示原函数，有如下几种方法计算梯度：
1. 根据梯度反推出另一个原函数，用那个原函数作为loss function计算梯度，常见操作如将 $ \nabla f(x) $ 替换成 $ f(x) \nabla log f(x) $
2. 根据梯度公式，通过冻结部分参数的方式实现梯度计算，即把不需要计算梯度的部分当作常数，将它们放在no_grad下计算

### 查看module的gradient
查看module参数的梯度:
```python
for name, param in model.named_parameters():
    if param.grad is not None:
        print(f"grad of param {name}: \n {param.grad}")
    else:
        print(f"param {name} has no grad")
```
### 两次调用loss backward后报错 计算图不能使用两次
看看是不是调用`optimizer.zero_grad()`后复用了前一个loss的计算图
每次清空梯度后需要从头开始计算下一个loss

### expand方法
*from GPT❤*

`.expand()` 函数在 PyTorch 中用于扩展张量的维度，使其在指定维度上重复，而不实际分配新的内存。这样可以在不增加内存使用的情况下，改变张量的形状。使用 `.expand()` 时，原始张量的内容不会被复制，而是通过广播机制（broadcasting）来实现。

主要特点包括：

1. 维度扩展: `.expand()` 可以将张量在指定的维度上扩展到更大的大小。例如，如果一个张量的形状是 `(1, 3)`，使用 `.expand(4, 3)` 将返回一个形状为 `(4, 3)` 的张量。

2. 不复制数据: 扩展后的张量与原始张量共享内存，因此不会增加内存占用。这对于大型张量的操作尤为重要。

3. 广播机制: `.expand()` 的使用依赖于广播机制，这意味着你可以将较小的张量与较大的张量相加或进行其他运算，而不会引发尺寸不匹配的错误。

假设你有一个形状为 `(1, 3)` 的张量：
```python
import torch

a = torch.tensor([[1, 2, 3]])  # shape: (1, 3)
b = a.expand(4, 3)              # shape: (4, 3)

print(b)
```
输出：
```
tensor([[1, 2, 3],
        [1, 2, 3],
        [1, 2, 3],
        [1, 2, 3]])
```
虽然 `b` 看起来包含了四个相同的行，但它实际上只是通过广播引用了 `a` 的数据，没有进行实际的内存复制。

nn.Parameter也可以使用expand方法实现对参数的维度扩展

## Markdown 
### 并排显示表格
1. html

```html
<p align="center">
    <img src="" alt="Image 1" width="45%" />
    <img src="" alt="Image 2" width="45%" />
</p>
```

2. table
```markdown
| ![Image 1](image1.png) | ![Image 2](image2.png) |
|------------------------|------------------------|
```

### 展示html代码块
注意\`\`\`前如果是html，需要空一行

## Python
### remove dirs
使用```os.removedirs(path)```会遇到检测到目录非空而无法删除的问题，可换成```shutil.rmtree(path)```，注意需要```import shutil```

### vars转dict
使用```vars()```可以转换特定对象为dict格式，等价于调用```object.__dict__()```，如将argparse返回的namespace转换成config dict

### 调用摄像头
```python
import numpy as np
import cv2

cap = cv2.VideoCapture(0)
w = int(cap.get(3))  # 获取视频的width
h = int(cap.get(4))  # 获取视频的height
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('output.avi',fourcc, 30.0, (w, h))

while(cap.isOpened()):
    ret, frame = cap.read()
    if ret==True:
        frame = cv2.flip(frame,1)
        out.write(frame) # 保存视频
        cv2.imshow('frame', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    else:
        break

cap.release()
out.release()
cv2.destroyAllWindows()
```
ref:[https://blog.csdn.net/qq_45779334/article/details/114676905](https://blog.csdn.net/qq_45779334/article/details/114676905)

### pdb调用栈
w或where查看当前调用栈
up和down在调用栈帧上下移动

### python dict 合并
方法 1：使用 `update()` 方法
将 `dict_b` 的键值对添加到 `dict_a` 中（此操作会直接修改 `dict_a`）。

```python
dict_a.update(dict_b)
```

此方法会在 `dict_a` 中更新或添加 `dict_b` 中的键值对，**原地修改 `dict_a`**，如果有相同的键，`dict_a` 中的值会被 `dict_b` 的值覆盖。

方法 2：使用解包运算符 `**`
可以通过创建一个新的字典，将 `dict_a` 和 `dict_b` 解包后合并在一起。

```python
merged_dict = {**dict_a, **dict_b}
```

这种方式不会修改原字典，而是创建了一个新的字典 `merged_dict`。如果存在相同的键，`dict_b` 中的值会覆盖 `dict_a` 的值。

方法 3：使用 `|` 运算符（Python 3.9+）
Python 3.9 及以上版本支持字典的并集运算符 `|`，可以直接用它合并两个字典。

```python
merged_dict = dict_a | dict_b
```

这种方式同样会生成一个新的字典 `merged_dict`，不会修改原字典，并且如果存在相同的键，`dict_b` 中的值会覆盖 `dict_a` 的值。

方法 4：使用字典生成式
可以通过字典生成式来合并两个字典，也可以实现更复杂的合并逻辑。

```python
merged_dict = {k: v for d in (dict_a, dict_b) for k, v in d.items()}
```

这个方式也会创建一个新的字典 `merged_dict`，并且 `dict_b` 中的值会覆盖 `dict_a` 中的值。

### 不重复随机数
如下例，生成10个1-100范围内不同的随机整数
```python
random_numbers = random.sample(range(1,101),10)
```


## Linux
### Shell同时输出到文件和控制台
```bash
<your program> | tee <your file path>
```
### 查看tcp端口占用
```bash
lsof -wni tcp:4000
```
### 递归删除当前目录下所有特定文件
*from GPT ❤*
```bash
find . -type f -name "<filename>" -exec rm -f {} +
```

命令解释：

- `find .`：在当前目录 (`.`) 及其子目录中查找文件。
- `-type f`：仅查找文件（不包含目录）。
- `-name "<filename>"`：仅查找文件名为 "\<filename\>" 的文件。
- `-exec rm -f {} +`：对查找到的每个文件执行删除命令 `rm -f`。`{}` 代表查找到的文件，`+` 表示批量处理。

